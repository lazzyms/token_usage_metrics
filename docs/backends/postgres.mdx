---
title: PostgreSQL Backend
description: "Reliable disk-based token usage tracking with PostgreSQL"
icon: "database"
---

## Overview

PostgreSQL backend provides ACID transactions and disk-based storage for long-term retention. Ideal for applications requiring data durability and complex queries.

<CardGroup cols={2}>
  <Card title="Performance" icon="gauge-high">
    ~2,000 writes/sec
  </Card>
  <Card title="Latency" icon="clock">
    &lt;20ms (p99)
  </Card>
</CardGroup>

## Installation

```bash
uv add token-usage-metrics[postgres]
```

## Setup

### Start PostgreSQL with Docker

```bash
# Basic setup
docker run -d -p 5432:5432 \
  -e POSTGRES_PASSWORD=yourpassword \
  -e POSTGRES_DB=token_usage \
  postgres:16-alpine

# With volume for persistence
docker run -d -p 5432:5432 \
  -v postgres-data:/var/lib/postgresql/data \
  -e POSTGRES_PASSWORD=yourpassword \
  -e POSTGRES_DB=token_usage \
  postgres:16-alpine
```

### Production Options

<Tabs>
  <Tab title="AWS RDS">
    ```bash
    postgresql://user:pass@your-instance.region.rds.amazonaws.com:5432/token_usage
    ```
  </Tab>

{" "}
<Tab title="Google Cloud SQL">
  ```bash
  postgresql://user:pass@/token_usage?host=/cloudsql/project:region:instance ```
</Tab>

  <Tab title="Azure Database">
    ```bash
    postgresql://user@server:pass@server.postgres.database.azure.com:5432/token_usage
    ```
  </Tab>
</Tabs>

## Usage Example

### Basic Usage

```python
import asyncio
from token_usage_metrics import TokenUsageClient

async def main():
    # Initialize with PostgreSQL
    dsn = "postgresql://user:password@localhost:5432/token_usage"
    client = await TokenUsageClient.init(dsn)

    # Log token usage
    await client.log(
        project="chatbot",
        request_type="chat",
        input_tokens=100,
        output_tokens=50
    )

    # Query events
    events, _ = await client.query(project="chatbot")
    print(f"Total events: {len(events)}")

    await client.aclose()

asyncio.run(main())
```

### With Metadata

```python
async def main():
    dsn = "postgresql://user:password@localhost:5432/token_usage"
    client = await TokenUsageClient.init(dsn)

    # Log with custom metadata
    await client.log(
        "my_app", "chat",
        input_tokens=150,
        output_tokens=75,
        metadata={
            "model": "gpt-4",
            "user_id": "alice",
            "session": "abc123"
        }
    )

    await client.aclose()
```

### Batch Logging

```python
async def main():
    dsn = "postgresql://user:password@localhost:5432/token_usage"
    client = await TokenUsageClient.init(dsn)

    # Log multiple events
    events = [
        {"project": "app1", "type": "chat", "input_tokens": 100, "output_tokens": 50},
        {"project": "app1", "type": "chat", "input_tokens": 120, "output_tokens": 60},
        {"project": "app2", "type": "embedding", "input_tokens": 200, "output_tokens": 0},
    ]

    for event in events:
        await client.log(
            event["project"],
            event["type"],
            input_tokens=event["input_tokens"],
            output_tokens=event["output_tokens"]
        )

    # Force flush
    await client.flush()

    await client.aclose()
```

### Query and Aggregate

```python
from datetime import datetime, timedelta, timezone

async def main():
    dsn = "postgresql://user:password@localhost:5432/token_usage"
    client = await TokenUsageClient.init(dsn)

    # Query recent events
    events, cursor = await client.query(
        project="chatbot",
        limit=100
    )

    # Get daily aggregates
    daily_stats = await client.aggregate(
        group_by="day",
        time_from=datetime.now(timezone.utc) - timedelta(days=7),
        project="chatbot"
    )

    print("Daily Usage:")
    for bucket in daily_stats:
        print(f"{bucket.start.date()}: {bucket.metrics['total_tokens']} tokens")

    await client.aclose()
```

## Configuration

### Environment Variables

```bash
export TUM_BACKEND=postgres
export TUM_POSTGRES_DSN=postgresql://user:password@localhost:5432/token_usage
export TUM_BUFFER_SIZE=1000
export TUM_FLUSH_INTERVAL=1.0
```

### Using Settings Object

```python
from token_usage_metrics import Settings, TokenUsageClient

settings = Settings(
    backend="postgres",
    postgres_dsn="postgresql://user:password@localhost:5432/token_usage",

    # Performance tuning
    buffer_size=1000,
    flush_interval=1.0,
    flush_batch_size=200,

    # Connection pooling
    postgres_pool_min_size=2,
    postgres_pool_max_size=10,
)

client = await TokenUsageClient.init(settings=settings)
```

## Data Retention

PostgreSQL stores data permanently until explicitly deleted:

```python
from datetime import datetime, timedelta, timezone
from token_usage_metrics import DeleteOptions

async def cleanup_old_data(client):
    """Delete data older than 90 days"""
    cutoff = datetime.now(timezone.utc) - timedelta(days=90)

    options = DeleteOptions(
        project_name="my_app",
        time_to=cutoff,
        include_aggregates=True
    )

    result = await client.delete_project(options)
    print(f"Deleted {result.events_deleted} events")
```

## Best Practices

<AccordionGroup>
  <Accordion title="Use Connection Pooling">
    Configure pool size for your workload:
    
    ```python
    settings = Settings(
        backend="postgres",
        postgres_dsn="postgresql://...",
        postgres_pool_min_size=5,
        postgres_pool_max_size=20
    )
    ```
  </Accordion>

{" "}
<Accordion title="Regular Maintenance">
  Run VACUUM and ANALYZE periodically: ```sql VACUUM ANALYZE usage_events;
  VACUUM ANALYZE daily_aggregates; ```
</Accordion>

  <Accordion title="Monitor Table Sizes">
    Check table sizes regularly:
    
    ```sql
    SELECT 
        relname as table_name,
        pg_size_pretty(pg_total_relation_size(relid)) as total_size
    FROM pg_catalog.pg_statio_user_tables
    ORDER BY pg_total_relation_size(relid) DESC;
    ```
  </Accordion>
</AccordionGroup>

<CardGroup cols={2}>
  <Card title="Previous: Redis" icon="bolt" href="/backends/redis">
    Redis backend documentation
  </Card>
  <Card title="Next: MongoDB" icon="leaf" href="/backends/mongodb">
    MongoDB backend documentation
  </Card>
</CardGroup>
