---
title: Supabase Backend
description: "Managed PostgreSQL with Supabase"
icon: "cloud"
---

## Overview

Supabase backend uses the same PostgreSQL implementation but leverages Supabase's managed infrastructure. Get all the benefits of PostgreSQL with automatic backups and a dashboard.

<Info>
  Supabase is PostgreSQL under the hood, so performance characteristics are
  identical to the PostgreSQL backend
</Info>

## Installation

```bash
uv add token-usage-metrics[postgres]
```

<Tip>Use the `postgres` extra, not a separate `supabase` extra</Tip>

## Setup

### 1. Create Supabase Project

1. Go to [supabase.com](https://supabase.com)
2. Create a new project
3. Wait for provisioning to complete
4. Get your connection string from Settings → Database

### 2. Get Connection String

From your Supabase dashboard:

**Settings → Database → Connection string → URI**

```
postgresql://postgres:[YOUR-PASSWORD]@db.[YOUR-PROJECT-REF].supabase.co:5432/postgres
```

<Warning>
  Use the service role key or a secure password. Never commit credentials to
  version control.
</Warning>

## Usage Example

### Basic Usage

```python
import asyncio
from token_usage_metrics import TokenUsageClient

async def main():
    # Initialize with Supabase connection
    dsn = "postgresql://postgres:[PASSWORD]@db.[PROJECT].supabase.co:5432/postgres"
    client = await TokenUsageClient.init(dsn)

    # Log token usage
    await client.log(
        project="chatbot",
        request_type="chat",
        input_tokens=100,
        output_tokens=50
    )

    # Query events
    events, _ = await client.query(project="chatbot")
    print(f"Total events: {len(events)}")

    await client.aclose()

asyncio.run(main())
```

### With Metadata

```python
async def main():
    dsn = "postgresql://postgres:[PASSWORD]@db.[PROJECT].supabase.co:5432/postgres"
    client = await TokenUsageClient.init(dsn)

    # Log with custom metadata
    await client.log(
        "my_app", "chat",
        input_tokens=150,
        output_tokens=75,
        metadata={
            "model": "gpt-4",
            "user_id": "alice",
            "session": "abc123"
        }
    )

    await client.aclose()
```

### Batch Logging

```python
async def main():
    dsn = "postgresql://postgres:[PASSWORD]@db.[PROJECT].supabase.co:5432/postgres"
    client = await TokenUsageClient.init(dsn)

    # Log multiple events
    events = [
        {"project": "app1", "type": "chat", "input_tokens": 100, "output_tokens": 50},
        {"project": "app1", "type": "chat", "input_tokens": 120, "output_tokens": 60},
        {"project": "app2", "type": "embedding", "input_tokens": 200, "output_tokens": 0},
    ]

    for event in events:
        await client.log(
            event["project"],
            event["type"],
            input_tokens=event["input_tokens"],
            output_tokens=event["output_tokens"]
        )

    # Force flush
    await client.flush()

    await client.aclose()
```

### Query and Aggregate

```python
from datetime import datetime, timedelta, timezone

async def main():
    dsn = "postgresql://postgres:[PASSWORD]@db.[PROJECT].supabase.co:5432/postgres"
    client = await TokenUsageClient.init(dsn)

    # Query recent events
    events, cursor = await client.query(
        project="chatbot",
        limit=100
    )

    # Get daily aggregates
    daily_stats = await client.aggregate(
        group_by="day",
        time_from=datetime.now(timezone.utc) - timedelta(days=7),
        project="chatbot"
    )

    print("Daily Usage:")
    for bucket in daily_stats:
        print(f"{bucket.start.date()}: {bucket.metrics['total_tokens']} tokens")

    await client.aclose()
```

## Configuration

### Environment Variables

```bash
export TUM_BACKEND=supabase
export TUM_SUPABASE_DSN=postgresql://postgres:[PASSWORD]@db.[PROJECT].supabase.co:5432/postgres
export TUM_BUFFER_SIZE=1000
export TUM_FLUSH_INTERVAL=1.0
```

### Using Settings Object

```python
from token_usage_metrics import Settings, TokenUsageClient

settings = Settings(
    backend="supabase",
    supabase_dsn="postgresql://postgres:[PASSWORD]@db.[PROJECT].supabase.co:5432/postgres",

    # Performance tuning
    buffer_size=1000,
    flush_interval=1.0,
    flush_batch_size=200,

    # Connection pooling
    postgres_pool_min_size=2,
    postgres_pool_max_size=10,
)

client = await TokenUsageClient.init(settings=settings)
```

## Supabase Dashboard

### Query Your Data

Use the SQL Editor in Supabase dashboard:

```sql
-- View recent events
SELECT * FROM usage_events
ORDER BY timestamp DESC
LIMIT 10;

-- Daily totals
SELECT
    date,
    SUM(total_tokens) as total_tokens,
    SUM(request_count) as requests
FROM daily_aggregates
WHERE date >= CURRENT_DATE - INTERVAL '30 days'
GROUP BY date
ORDER BY date;
```

## Data Retention

Set up automatic cleanup with pg_cron:

```python
from datetime import datetime, timedelta, timezone
from token_usage_metrics import DeleteOptions

async def cleanup_old_data(client):
    """Delete data older than 90 days"""
    cutoff = datetime.now(timezone.utc) - timedelta(days=90)

    options = DeleteOptions(
        project_name="my_app",
        time_to=cutoff,
        include_aggregates=True
    )

    result = await client.delete_project(options)
    print(f"Deleted {result.events_deleted} events")
```

## Best Practices

<AccordionGroup>
  <Accordion title="Use Service Role Key">
    Use the service role key for backend operations:
    
    ```python
    # ✅ Good - service role
    supabase_dsn="postgresql://postgres:service_role_key@..."
    
    # ❌ Bad - anon key (read-only)
    supabase_dsn="postgresql://postgres:anon_key@..."
    ```
  </Accordion>

{" "}
<Accordion title="Store Credentials Securely">
  Use environment variables: ```python import os settings = Settings(
  backend="supabase", supabase_dsn=os.getenv("SUPABASE_DSN") ) ```
</Accordion>

  <Accordion title="Use Connection Pooler">
    For serverless environments, use port 6543:
    
    ```bash
    postgresql://postgres:[PASSWORD]@db.[PROJECT].supabase.co:6543/postgres
    ```
  </Accordion>
</AccordionGroup>

## Advantages

<CardGroup cols={2}>
  <Card title="Managed Backups" icon="floppy-disk">
    Automatic daily backups included
  </Card>
  <Card title="Dashboard" icon="chart-line">
    Visual query editor and monitoring
  </Card>
  <Card title="Easy Scaling" icon="up-right-and-down-left-from-center">
    Upgrade plan to scale resources
  </Card>
  <Card title="No Maintenance" icon="wrench">
    Updates handled automatically
  </Card>
</CardGroup>

<Card title="Previous: MongoDB" icon="leaf" href="/backends/mongodb">
  MongoDB backend documentation
</Card>
