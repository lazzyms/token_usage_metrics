---
title: Contribution Guidelines
description: "How to contribute to Token Usage Metrics"
icon: "hand-holding-heart"
---

## Thanks for considering a contribution

We welcome contributions of all kinds: bug reports, documentation improvements, tests, and code changes. This document explains how to get started and the project's expectations.

**Quick links**

- Code of Conduct: https://www.contributor-covenant.org/version/2/1/code_of_conduct/
- Issues: https://github.com/lazzyms/token_usage_metrics/issues
- Discussions: https://github.com/lazzyms/token_usage_metrics/discussions

## Before you start

1. Search existing issues and discussions â€” someone may already be working on the same thing.
2. If you're planning a large change or new feature, open an issue first to discuss the design.

## How to report bugs

When opening an issue, please include:

- A clear and descriptive title
- What you expected to happen and what actually happened
- Steps to reproduce (small, copy/pasteable example when possible)
- Environment information (OS, Python version, backend used)
- Relevant logs or error messages

Use the `bug report` issue template when possible.

## How to request features

Open a feature request with the following info:

- Problem you're trying to solve
- Suggested behavior / API
- Priority (High / Medium / Low)
- Any relevant constraints (e.g., backend, performance)

Use the `feature request` issue template when possible.

## Development setup

Clone your fork and install dev dependencies:

```bash
git clone https://github.com/YOUR_USERNAME/token_usage_metrics.git
cd token_usage_metrics

# Install dependencies using uv (project uses Astral/uv tool)
uv sync

# Install dev extras
uv sync --all-extras
```

If you prefer `pip`/`venv`, create an environment and install from `pyproject.toml`.

## Coding style

- Follow PEP 8 for Python code
- Use type hints where appropriate
- Keep functions small and focused
- Prefer clear, well-tested implementations over clever ones
- For formatting and linting, run:

```bash
uv run ruff format .
uv run ruff check .
uv run mypy token_usage_metrics
```

## Tests

- Add tests for new features and bug fixes.
- Use `pytest` and mark async tests with `pytest.mark.asyncio`.
- Run tests locally:

```bash
uv run pytest
uv run pytest --maxfail=1 -q
```

## Branching & commits

- Create a descriptive branch:

```bash
git checkout -b feat/short-description
```

- Use conventional commit messages (examples):

  - `feat: add postgres bulk-upsert`
  - `fix: handle empty metadata in log()`
  - `docs: update redis backend examples`

## Pull request checklist

Before requesting review, ensure your PR includes:

- [ ] Updated or new tests
- [ ] Code is formatted and linted
- [ ] Type checks pass
- [ ] Updated documentation (if applicable)
- [ ] A clear PR description explaining the why and what

Please open a draft PR if the work is ongoing and you want early feedback.

## Adding a new backend

If you want to add support for a new database backend, please follow these steps:

1. Open an issue to discuss requirements and schema design.
2. Implement a backend class under `token_usage_metrics/backends/` implementing the `Backend` interface.
3. Add the backend to the backend factory and `BackendType` enum.
4. Add tests under `tests/` (unit and integration where applicable).
5. Add a short `docs/backends/<name>.mdx` describing setup and usage.

## Security

If you discover a security vulnerability, please do not open a public issue. Instead, report it privately to the repository owner via security contact or email.

## Code of Conduct

Be respectful and inclusive. We follow the Contributor Covenant Code of Conduct.

## License

By contributing, you agree your contributions will be licensed under the project's MIT license.

---

Thank you â€” contributions are what make open source great! ðŸŽ‰
